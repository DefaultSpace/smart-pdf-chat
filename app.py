import streamlit as st
import os
from pdf_handler import extract_pages_from_pdf, chunk_pages, get_pdf_page_image_bytes
import fitz
from embedder import embed_and_store, load_vectorstore
from chatbot import get_qa_chain, generate_suggested_questions, summarize_documents, extract_keywords_from_documents, generate_concept_map_data, extract_timeline_from_documents
import json
import pandas as pd # Grafik iÃ§in Pandas ekleyelim
from collections import defaultdict # Chunk sayÄ±sÄ±nÄ± saymak iÃ§in

st.set_page_config(page_title="PDF Chatbot", layout="wide")

# Session state'i baÅŸlat
if 'pdf_previews' not in st.session_state:
    st.session_state.pdf_previews = {}
if 'last_question' not in st.session_state:
    st.session_state.last_question = ""
if 'last_answer' not in st.session_state:
    st.session_state.last_answer = ""
if 'refined_answer' not in st.session_state:
    st.session_state.refined_answer = ""
if 'source_documents' not in st.session_state:
    st.session_state.source_documents = []
if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []
if 'suggested_questions' not in st.session_state:
    st.session_state.suggested_questions = []
if 'current_question_input' not in st.session_state:
    st.session_state.current_question_input = ""
if 'document_summary' not in st.session_state:
    st.session_state.document_summary = ""
if 'extracted_keywords' not in st.session_state:
    st.session_state.extracted_keywords = []
if 'concept_map_data' not in st.session_state:
    st.session_state.concept_map_data = ""
if 'timeline_data' not in st.session_state:
    st.session_state.timeline_data = ""
if 'page_chunk_counts' not in st.session_state: # Bilgi yoÄŸunluÄŸu iÃ§in session state
    st.session_state.page_chunk_counts = {}


st.title("ğŸ“„ PDF Destekli Rol-TabanlÄ± Chatbot")

st.info(
    "ğŸ”’ **Veri GizliliÄŸi ve GÃ¼venlik:** Bu uygulama tamamen yerel makinenizde Ã§alÄ±ÅŸÄ±r. "
    "YÃ¼klediÄŸiniz PDF'ler ve sorduÄŸunuz sorular harici bir sunucuya gÃ¶nderilmez. "
    "TÃ¼m iÅŸlemler (metin Ã§Ä±karma, embedding, cevap Ã¼retme) Ollama ve yerel modeliniz (Qwen2.5) aracÄ±lÄ±ÄŸÄ±yla bilgisayarÄ±nÄ±zda gerÃ§ekleÅŸtirilir."
)
st.markdown("---")

# Rol seÃ§imi
roles_data = json.load(open("roles.json", "r", encoding="utf-8"))
available_roles = roles_data
selected_role_from_list = st.selectbox("ğŸ§‘ HazÄ±r Rollerden SeÃ§", [""] + available_roles, index=0, help="Bir rol seÃ§in veya aÅŸaÄŸÄ±ya kendi rolÃ¼nÃ¼zÃ¼ yazÄ±n.")

custom_role_input = st.text_area("ğŸ“ Veya Kendi RolÃ¼nÃ¼ Yaz (isteÄŸe baÄŸlÄ±)", placeholder="Ã–rn: 'Belgelerdeki finansal riskleri analiz eden bir finans uzmanÄ±.'")

# Nihai rolÃ¼ belirle
final_selected_role = custom_role_input.strip() if custom_role_input.strip() else selected_role_from_list

if not final_selected_role:
    st.warning("âš ï¸ LÃ¼tfen bir rol seÃ§in veya kendi rolÃ¼nÃ¼zÃ¼ yazÄ±n.")
    st.stop()

st.info(f"ğŸ¤– Aktif Rol: {final_selected_role}")

# Cevap dili seÃ§imi
available_languages = {"TÃ¼rkÃ§e": "tr", "English": "en"}
selected_language_label = st.selectbox("ğŸŒ Cevap Dili SeÃ§", list(available_languages.keys()))
selected_language_code = available_languages[selected_language_label]


# PDF yÃ¼kleme
uploaded_files = st.file_uploader("ğŸ“¤ PDF YÃ¼kle (Birden fazla dosya seÃ§ebilirsiniz)", type=["pdf"], accept_multiple_files=True)
processed_pdf_paths = []
all_chunks_for_session = [] # Bu session'daki tÃ¼m chunk'larÄ± saklamak iÃ§in

if uploaded_files:
    # Yeni yÃ¼kleme olduÄŸunda bazÄ± session state'leri sÄ±fÄ±rla
    st.session_state.pdf_previews = {}
    st.session_state.suggested_questions = []
    st.session_state.document_summary = ""
    st.session_state.extracted_keywords = []
    st.session_state.concept_map_data = ""
    st.session_state.timeline_data = ""
    st.session_state.page_chunk_counts = {} # Bilgi yoÄŸunluÄŸunu da sÄ±fÄ±rla
    st.session_state.last_answer = ""
    st.session_state.refined_answer = ""
    st.session_state.source_documents = []

    current_file_chunks = []
    data_dir = "data"
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)

    for uploaded_file in uploaded_files:
        file_path = os.path.join(data_dir, uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.read())
        processed_pdf_paths.append(file_path)

        try:
            doc = fitz.open(file_path)
            st.session_state.pdf_previews[uploaded_file.name] = {
                "total_pages": doc.page_count,
                "current_page_display": 1,
                "path": file_path
            }
            doc.close()
        except Exception as e:
            st.error(f"{uploaded_file.name} iÃ§in sayfa sayÄ±sÄ± alÄ±namadÄ±: {e}")
            continue

        pages_data = extract_pages_from_pdf(file_path)
        if pages_data:
            chunks_from_file = chunk_pages(pages_data)
            current_file_chunks.extend(chunks_from_file)
            st.write(f"ğŸ“„ {uploaded_file.name} ({st.session_state.pdf_previews.get(uploaded_file.name, {}).get('total_pages', 'N/A')} sayfa) iÅŸlendi ({len(chunks_from_file)} chunk).")
        else:
            st.write(f"âš ï¸ {uploaded_file.name} dosyasÄ±ndan metin Ã§Ä±karÄ±lamadÄ± veya dosya boÅŸ.")

    all_chunks_for_session = current_file_chunks

    if all_chunks_for_session:
        # Bilgi yoÄŸunluÄŸu hesaplamasÄ±
        page_counts = defaultdict(lambda: defaultdict(int))
        for chunk in all_chunks_for_session:
            source = chunk.metadata.get("source", "Bilinmeyen Kaynak")
            page = chunk.metadata.get("page", 0) # Sayfa no yoksa 0 varsayalÄ±m
            if page > 0: # GeÃ§erli sayfa numarasÄ± varsa say
                page_counts[source][page] += 1
        st.session_state.page_chunk_counts = {k: dict(v) for k, v in page_counts.items()} # defaultdict'u dict'e Ã§evir

        # Embedding ve diÄŸer iÅŸlemler
        if not os.path.exists("vectordb"):
            os.makedirs("vectordb")
        embed_and_store(all_chunks_for_session)
        st.success("âœ… TÃ¼m PDF'ler iÅŸlendi ve veritabanÄ± oluÅŸturuldu/gÃ¼ncellendi!")

        with st.spinner("ğŸ¤” Ã–rnek sorular ve anahtar kelimeler hazÄ±rlanÄ±yor..."):
            st.session_state.suggested_questions = generate_suggested_questions(all_chunks_for_session, final_selected_role, selected_language_code, num_questions=3)
            st.session_state.extracted_keywords = extract_keywords_from_documents(all_chunks_for_session, final_selected_role, selected_language_code, num_keywords=10)
    else:
        st.warning("âš ï¸ YÃ¼klenen PDF'lerden metin Ã§Ä±karÄ±lamadÄ± veya PDF'ler boÅŸ.")
        st.session_state.suggested_questions = []
        st.session_state.extracted_keywords = []
        st.session_state.concept_map_data = ""
        st.session_state.timeline_data = ""
        st.session_state.page_chunk_counts = {}


# PDF Ã–nizleme AlanÄ±
if st.session_state.pdf_previews:
    st.markdown("---")
    st.subheader("ğŸ“‚ YÃ¼klenen PDF'ler ve Ã–nizleme")
    for pdf_name, preview_data in st.session_state.pdf_previews.items():
        with st.expander(f"{pdf_name} ({preview_data['total_pages']} sayfa)"):
            if preview_data['total_pages'] > 0:
                page_to_show_user = st.number_input(
                    f"Sayfa NumarasÄ± (1-{preview_data['total_pages']})",
                    min_value=1,
                    max_value=preview_data['total_pages'],
                    value=preview_data['current_page_display'],
                    key=f"preview_page_num_{pdf_name}"
                )
                st.session_state.pdf_previews[pdf_name]['current_page_display'] = page_to_show_user
                page_num_fitz = page_to_show_user - 1

                texts_to_highlight_on_page = []
                if st.session_state.source_documents:
                    for src_doc in st.session_state.source_documents:
                        if src_doc.metadata.get('source') == pdf_name and \
                           src_doc.metadata.get('page') == page_to_show_user:
                            texts_to_highlight_on_page.append(src_doc.page_content)

                img_bytes = get_pdf_page_image_bytes(preview_data['path'], page_num_fitz, texts_to_highlight_on_page)
                if img_bytes:
                    st.image(img_bytes, caption=f"{pdf_name} - Sayfa {page_to_show_user}{' (vurgulandÄ±)' if texts_to_highlight_on_page else ''}", use_column_width=True)
                else:
                    st.warning(f"{pdf_name} - Sayfa {page_to_show_user} iÃ§in Ã¶nizleme oluÅŸturulamadÄ±.")
            else:
                st.info(f"{pdf_name} iÃ§eriÄŸi boÅŸ veya okunamadÄ±.")

# Bilgi YoÄŸunluÄŸu Analizi AlanÄ±
if st.session_state.page_chunk_counts:
    st.markdown("---")
    st.subheader("ğŸ“Š Bilgi YoÄŸunluÄŸu (Sayfa BaÅŸÄ±na Chunk SayÄ±sÄ±)")
    for pdf_name, counts in st.session_state.page_chunk_counts.items():
        with st.expander(f"{pdf_name} - YoÄŸunluk GrafiÄŸi"):
            if counts:
                # GrafiÄŸi Ã§izmek iÃ§in veriyi hazÄ±rla (sayfa numarasÄ±na gÃ¶re sÄ±ralÄ±)
                sorted_counts = dict(sorted(counts.items()))
                # Pandas DataFrame oluÅŸturmak daha saÄŸlam olabilir ama dict ile deneyelim
                # st.bar_chart(pd.DataFrame.from_dict(sorted_counts, orient='index', columns=['Chunk SayÄ±sÄ±']))
                st.bar_chart(sorted_counts)
            else:
                st.info(f"{pdf_name} iÃ§in yoÄŸunluk verisi hesaplanamadÄ±.")


# Soru alanÄ± ve diÄŸer iÅŸlemler (Sadece PDF'ler yÃ¼klendi ve iÅŸlendiyse gÃ¶ster)
if uploaded_files and all_chunks_for_session:
    # Anahtar Kelimeler (Kenar Ã‡ubuÄŸunda)
    if st.session_state.extracted_keywords:
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ”‘ Anahtar Kelimeler")
        for kw in st.session_state.extracted_keywords:
            st.sidebar.caption(kw)

    # Ã–rnek Sorular
    if st.session_state.suggested_questions:
        st.markdown("---")
        st.subheader("ğŸ’¡ Ã–rnek Sorular")
        num_suggestion_cols = min(len(st.session_state.suggested_questions), 3)
        if num_suggestion_cols > 0:
            cols = st.columns(num_suggestion_cols)
            for i, sq in enumerate(st.session_state.suggested_questions):
                with cols[i % num_suggestion_cols]:
                    if st.button(sq, key=f"suggested_q_{i}", use_container_width=True):
                        st.session_state.current_question_input = sq
                        st.experimental_rerun()

    # Soru GiriÅŸ AlanÄ±
    question = st.text_input("â“ Soru Sor", value=st.session_state.current_question_input, key="main_question_input_field")
    if st.session_state.main_question_input_field != st.session_state.current_question_input:
        st.session_state.current_question_input = st.session_state.main_question_input_field
        st.experimental_rerun()

    # Aksiyon ButonlarÄ±
    action_cols = st.columns(4)
    with action_cols[0]: # YanÄ±tla Butonu
        if st.button("ğŸ’¬ YanÄ±tla", use_container_width=True) and st.session_state.current_question_input:
            st.session_state.last_question = st.session_state.current_question_input
            st.session_state.refined_answer = ""
            st.session_state.document_summary = ""
            st.session_state.concept_map_data = ""
            st.session_state.timeline_data = ""
            vectorstore = load_vectorstore()
            if vectorstore:
                with st.spinner("YanÄ±t hazÄ±rlanÄ±yor..."):
                    qa_chain = get_qa_chain(vectorstore, final_selected_role, selected_language_code)
                    input_data = {"query": st.session_state.current_question_input}
                    response_data = qa_chain.invoke(input_data)
                    current_answer = response_data["result"]
                    current_sources = response_data.get("source_documents", [])
                    st.session_state.last_answer = current_answer
                    st.session_state.source_documents = current_sources
                    st.session_state.conversation_history.append({
                        "question": st.session_state.current_question_input, "answer": current_answer, "sources": current_sources,
                        "role": final_selected_role, "language": selected_language_label, "refined_answer": ""
                    })
            else:
                st.error("âŒ VektÃ¶r veritabanÄ± yÃ¼klenemedi. LÃ¼tfen PDF yÃ¼kleyip iÅŸleyin.")
                st.session_state.last_answer = ""
                st.session_state.source_documents = []

    with action_cols[1]: # Ã–zetle Butonu
        if st.button("ğŸ§® Ã–zetle", use_container_width=True):
            st.session_state.last_answer = ""
            st.session_state.refined_answer = ""
            st.session_state.source_documents = []
            st.session_state.concept_map_data = ""
            st.session_state.timeline_data = ""
            if all_chunks_for_session:
                with st.spinner("ğŸ“š Belgeler Ã¶zetleniyor... Bu iÅŸlem biraz zaman alabilir."):
                    summary = summarize_documents(all_chunks_for_session, final_selected_role, selected_language_code)
                    st.session_state.document_summary = summary
            else:
                st.warning("âš ï¸ Ã–zetlenecek belge bulunamadÄ±. LÃ¼tfen Ã¶nce PDF yÃ¼kleyin.")
                st.session_state.document_summary = ""

    with action_cols[2]: # Konsept HaritasÄ± Butonu
        if st.button("ğŸ§  Konsept HaritasÄ±", use_container_width=True):
            st.session_state.last_answer = ""
            st.session_state.refined_answer = ""
            st.session_state.source_documents = []
            st.session_state.document_summary = ""
            st.session_state.timeline_data = ""
            if all_chunks_for_session:
                with st.spinner("ğŸ—ºï¸ Konsept haritasÄ± oluÅŸturuluyor..."):
                    map_data = generate_concept_map_data(all_chunks_for_session, final_selected_role, selected_language_code)
                    st.session_state.concept_map_data = map_data
            else:
                st.warning("âš ï¸ Konsept haritasÄ± iÃ§in belge bulunamadÄ±. LÃ¼tfen Ã¶nce PDF yÃ¼kleyin.")
                st.session_state.concept_map_data = ""

    with action_cols[3]: # Zaman Ã‡izelgesi Butonu
        if st.button("â³ Zaman Ã‡izelgesi", use_container_width=True):
            st.session_state.last_answer = ""
            st.session_state.refined_answer = ""
            st.session_state.source_documents = []
            st.session_state.document_summary = ""
            st.session_state.concept_map_data = ""
            if all_chunks_for_session:
                with st.spinner("ğŸ“… Zaman Ã§izelgesi Ã§Ä±karÄ±lÄ±yor..."):
                    timeline = extract_timeline_from_documents(all_chunks_for_session, final_selected_role, selected_language_code)
                    st.session_state.timeline_data = timeline
            else:
                st.warning("âš ï¸ Zaman Ã§izelgesi iÃ§in belge bulunamadÄ±. LÃ¼tfen Ã¶nce PDF yÃ¼kleyin.")
                st.session_state.timeline_data = ""


    # Ã‡Ä±ktÄ± AlanlarÄ±
    st.markdown("---") # AyÄ±rÄ±cÄ±

    # Belge Ã–zeti GÃ¶sterimi
    if st.session_state.document_summary:
        st.markdown("### ğŸ“œ Belge Ã–zeti")
        st.write(st.session_state.document_summary)

    # Konsept HaritasÄ± GÃ¶sterimi
    if st.session_state.concept_map_data:
        st.markdown("### ğŸ—ºï¸ Konsept HaritasÄ±")
        if "```mermaid" in st.session_state.concept_map_data:
            st.markdown(st.session_state.concept_map_data)
        else:
            st.warning("Konsept haritasÄ± gÃ¶rselleÅŸtirilemedi. Ham veri:")
            st.code(st.session_state.concept_map_data)

    # Zaman Ã‡izelgesi GÃ¶sterimi
    if st.session_state.timeline_data:
        st.markdown("### ğŸ“… Zaman Ã‡izelgesi")
        st.markdown(st.session_state.timeline_data)


    # Cevap ve Ä°lgili Ä°ÅŸlemler GÃ¶sterimi
    if st.session_state.last_answer:
        st.markdown("### ğŸ’¡ GÃ¼ncel Cevap")
        st.write(st.session_state.last_answer)

        col_refine1, col_refine2 = st.columns(2)
        with col_refine1:
            if st.button("ğŸ” CevabÄ± DetaylandÄ±r"):
                from chatbot import refine_answer
                if st.session_state.last_question and st.session_state.last_answer:
                    with st.spinner("Cevap detaylandÄ±rÄ±lÄ±yor..."):
                        refined_text = refine_answer(st.session_state.last_question, st.session_state.last_answer, "detaylandÄ±r", final_selected_role, selected_language_code)
                        st.session_state.refined_answer = refined_text
                        if st.session_state.conversation_history:
                            st.session_state.conversation_history[-1]["refined_answer"] = refined_text
                else:
                    st.warning("DetaylandÄ±rmak iÃ§in Ã¶nce bir cevap alÄ±nmalÄ±.")
        with col_refine2:
            if st.button("ğŸ”€ CevabÄ± SadeleÅŸtir"):
                from chatbot import refine_answer
                if st.session_state.last_question and st.session_state.last_answer:
                     with st.spinner("Cevap sadeleÅŸtiriliyor..."):
                        refined_text = refine_answer(st.session_state.last_question, st.session_state.last_answer, "sadeleÅŸtir", final_selected_role, selected_language_code)
                        st.session_state.refined_answer = refined_text
                        if st.session_state.conversation_history:
                            st.session_state.conversation_history[-1]["refined_answer"] = refined_text
                else:
                    st.warning("SadeleÅŸtirmek iÃ§in Ã¶nce bir cevap alÄ±nmalÄ±.")

        if st.session_state.refined_answer:
            st.markdown("#### âœ¨ GÃ¼ncel DÃ¼zenlenmiÅŸ Cevap:")
            st.write(st.session_state.refined_answer)

        if st.session_state.source_documents:
            st.markdown("ğŸ“š **Referanslar:**")
            references = set()
            for doc in st.session_state.source_documents:
                source_name = doc.metadata.get("source", "Bilinmeyen Kaynak")
                page_number = doc.metadata.get("page", "Bilinmeyen Sayfa")
                references.add(f"- {source_name} (Sayfa: {page_number})")
            for ref in sorted(list(references)):
                st.markdown(ref)

# KonuÅŸma GeÃ§miÅŸi (Kenar Ã‡ubuÄŸunda)
st.sidebar.title("ğŸ“œ KonuÅŸma GeÃ§miÅŸi")
if not st.session_state.conversation_history:
    st.sidebar.info("HenÃ¼z bir konuÅŸma geÃ§miÅŸi yok.")
else:
    for i, entry in enumerate(reversed(st.session_state.conversation_history)):
        with st.sidebar.expander(f"Soru {len(st.session_state.conversation_history) - i}: {entry['question'][:30]}..."):
            st.markdown(f"**Soru:** {entry['question']}")
            st.markdown(f"**Rol:** {entry['role']}")
            st.markdown(f"**Dil:** {entry['language']}")
            st.markdown("**Cevap:**")
            st.write(entry['answer'])
            if entry.get('refined_answer'):
                st.markdown("**DÃ¼zenlenmiÅŸ Cevap:**")
                st.write(entry['refined_answer'])
            if entry['sources']:
                st.markdown("**Referanslar:**")
                current_references = set()
                for doc_ref in entry['sources']:
                    source_name_ref = doc_ref.metadata.get("source", "Bilinmeyen Kaynak")
                    page_number_ref = doc_ref.metadata.get("page", "Bilinmeyen Sayfa")
                    current_references.add(f"- {source_name_ref} (Sayfa: {page_number_ref})")
                for r_ref in sorted(list(current_references)):
                    st.markdown(r_ref)
